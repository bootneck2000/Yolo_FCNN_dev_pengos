{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bootneck2000/Yolo_FCNN_dev_pengos/blob/main/Faster_RCNN_Roldan_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fbb7d189-e51d-4a08-b9a3-9b93db4880a3",
      "metadata": {
        "id": "fbb7d189-e51d-4a08-b9a3-9b93db4880a3"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install required packages (if not already installed)\n",
        "#!pip install torch torchvision requests opencv-python tqdm pillow\n",
        "#!pip install --upgrade numpy==1.26.4\n",
        "# Cell 2: Imports\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Cell 3: Utility to download and extract Roboflow YOLOv8 export\n",
        "def download_and_extract_roboflow_zip(roboflow_zip_url, extract_to=\"roboflow_dataset\"):\n",
        "    if os.path.exists(extract_to):\n",
        "        print(f\"'{extract_to}' already exists, skipping download.\")\n",
        "        return\n",
        "    print(\"Downloading dataset from Roboflow...\")\n",
        "    r = requests.get(roboflow_zip_url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(extract_to)\n",
        "    print(f\"Dataset extracted to '{extract_to}'.\")\n",
        "\n",
        "# Cell 4: YOLOv8 to COCO box conversion (helper)\n",
        "def yolo_to_coco(bbox, img_w, img_h):\n",
        "    # bbox: [x_center, y_center, width, height] normalized\n",
        "    x_c, y_c, w, h = bbox\n",
        "    x_c *= img_w\n",
        "    y_c *= img_h\n",
        "    w *= img_w\n",
        "    h *= img_h\n",
        "    # Convert to [xmin, ymin, xmax, ymax]\n",
        "    xmin = x_c - w / 2\n",
        "    ymin = y_c - h / 2\n",
        "    xmax = x_c + w / 2\n",
        "    ymax = y_c + h / 2\n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "# Cell 5: Roboflow YOLO8 Dataset\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "class RoboflowYolo8Dataset(Dataset):\n",
        "    def __init__(self, data_dir, split=\"train\", transforms=None):\n",
        "        # ... (directory finding code as before) ...\n",
        "        self.images_dir = os.path.join(data_dir, split, \"images\")\n",
        "        self.labels_dir = os.path.join(data_dir, split, \"labels\")\n",
        "        self.img_filenames = [f for f in os.listdir(self.images_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Build class_dict from all label files\n",
        "        self.class_dict = self._find_classes()\n",
        "\n",
        "    def _find_classes(self):\n",
        "        classes = set()\n",
        "        for label_file in os.listdir(self.labels_dir):\n",
        "            with open(os.path.join(self.labels_dir, label_file)) as f:\n",
        "                for line in f:\n",
        "                    if line.strip():\n",
        "                        parts = line.strip().split()\n",
        "                        classes.add(int(parts[0]))\n",
        "        sorted_classes = sorted(list(classes))\n",
        "        return {idx: idx for idx in sorted_classes}  # assumes contiguous class ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ... (rest of your code, as in previous examples) ...\n",
        "        img_name = self.img_filenames[idx]\n",
        "        img_path = os.path.join(self.images_dir, img_name)\n",
        "        label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.labels_dir, label_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        w, h = image.size\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    if line.strip():\n",
        "                        parts = line.strip().split()\n",
        "                        cls, xc, yc, bw, bh = map(float, parts[:5])\n",
        "                        xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "                        x1 = xc - bw/2\n",
        "                        y1 = yc - bh/2\n",
        "                        x2 = xc + bw/2\n",
        "                        y2 = yc + bh/2\n",
        "                        boxes.append([x1, y1, x2, y2])\n",
        "                        labels.append(int(cls))\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        if boxes.numel() == 0:\n",
        "            return None\n",
        "\n",
        "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([idx])}\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        else:\n",
        "            image = F.to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_filenames)\n",
        "\n",
        "def __getitem__(self, idx):\n",
        "    img_name = self.img_filenames[idx]\n",
        "    img_path = os.path.join(self.images_dir, img_name)\n",
        "    label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
        "    label_path = os.path.join(self.labels_dir, label_name)\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    w, h = image.size\n",
        "\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    parts = line.strip().split()\n",
        "                    cls, xc, yc, bw, bh = map(float, parts)\n",
        "                    xc, yc, bw, bh = xc * w, yc * h, bw * w, bh * h\n",
        "                    x1 = xc - bw / 2\n",
        "                    y1 = yc - bh / 2\n",
        "                    x2 = xc + bw / 2\n",
        "                    y2 = yc + bh / 2\n",
        "                    boxes.append([x1, y1, x2, y2])\n",
        "                    labels.append(int(cls))\n",
        "\n",
        "    boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "    if boxes.numel() == 0:   # <-- FIX: Check boxes before using target!\n",
        "        return None\n",
        "\n",
        "    target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([idx])}\n",
        "\n",
        "    if self.transforms:\n",
        "        image = self.transforms(image)\n",
        "    else:\n",
        "        image = F.to_tensor(image)\n",
        "    return image, target\n",
        "\n",
        "# Cell 6: Helper for collate_fn (required by DataLoader)\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5af63557-92d2-456f-a93e-5d40c2a40ba9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5af63557-92d2-456f-a93e-5d40c2a40ba9",
        "outputId": "6e5681d5-90c7-4ab3-82b5-dd55d6827b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Extracting dataset...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (uncomment if not already installed)\n",
        "# !pip install roboflow\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Download and extract Roboflow ZIP\n",
        "#ROBOFLOW_ZIP_URL = \"https://app.roboflow.com/ds/VquXPr9PVz?key=QyrlUzVsjR\"\n",
        "ROBOFLOW_ZIP_URL = \"https://app.roboflow.com/ds/sU8uW5aryJ?key=zytgPCj2cT\"\n",
        "DATASET_DIR = \"roboflow_dataset\"\n",
        "ZIP_PATH = \"roboflow.zip\"\n",
        "\n",
        "def download_and_extract_roboflow_zip(url, extract_to):\n",
        "    # Download the dataset\n",
        "    print(\"Downloading dataset...\")\n",
        "    r = requests.get(url)\n",
        "    with open(ZIP_PATH, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    # Extract the zip file\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Done.\")\n",
        "\n",
        "download_and_extract_roboflow_zip(ROBOFLOW_ZIP_URL, DATASET_DIR)\n",
        "\n",
        "# Prepare train/val datasets and dataloaders\n",
        "# You need to define or import RoboflowYolo8Dataset and collate_fn as in your original code\n",
        "\n",
        "train_dataset = RoboflowYolo8Dataset(DATASET_DIR, split=\"train\")\n",
        "# val_dataset = RoboflowYolo8Dataset(DATASET_DIR, split=\"valid\")\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edaaef3b-581b-4f4a-abe0-a4887cb9f360",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edaaef3b-581b-4f4a-abe0-a4887cb9f360",
        "outputId": "f9f8fe12-0c2c-4073-915f-ac8f16fca4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 115/115 [04:00<00:00,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 18.0461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 115/115 [04:03<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 10.2051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  84%|████████▍ | 97/115 [03:24<00:39,  2.19s/it]"
          ]
        }
      ],
      "source": [
        "# Cell 8: Prepare the model\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch:\n",
        "        return None, None\n",
        "    images, targets = zip(*batch)\n",
        "    return list(images), list(targets)\n",
        "\n",
        "def get_fasterrcnn_model(num_classes):\n",
        "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "num_classes = len(train_dataset.class_dict) + 1  # +1 for background\n",
        "model = get_fasterrcnn_model(num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Cell 9: Training loop\n",
        "def train():\n",
        "    data_dir = \"roboflow_dataset\"  # Set this to your dataset location\n",
        "    num_epochs = 10\n",
        "    batch_size = 4\n",
        "\n",
        "    # Build datasets and loaders\n",
        "    train_dataset = RoboflowYolo8Dataset(data_dir, split=\"train\")\n",
        "   #val_dataset = RoboflowYolo8Dataset(data_dir, split=\"val\")\n",
        "    num_classes = len(train_dataset.class_dict) + 1  # +1 for background\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "   # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = get_fasterrcnn_model(num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params, lr=1e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            if images is None or targets is None:\n",
        "                continue\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += losses.item()\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Epoch {epoch+1} Loss: {running_loss:.4f}\")\n",
        "\n",
        "        # Optionally: validation loop here\n",
        "\n",
        "    # Save trained model\n",
        "    torch.save(model.state_dict(), \"fasterrcnn_roboflow_yolov8.pth\")\n",
        "    print(\"Training complete. Model saved as fasterrcnn_roboflow_yolov8.pth.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}