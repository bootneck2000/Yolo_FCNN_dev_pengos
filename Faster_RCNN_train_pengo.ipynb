{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bootneck2000/Yolo_FCNN_dev_pengos/blob/main/Faster_RCNN_train_pengo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb7d189-e51d-4a08-b9a3-9b93db4880a3",
      "metadata": {
        "id": "fbb7d189-e51d-4a08-b9a3-9b93db4880a3"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install required packages (if not already installed)\n",
        "#!pip install torch torchvision requests opencv-python tqdm pillow\n",
        "#!pip install --upgrade numpy==1.26.4\n",
        "# Cell 2: Imports\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Cell 3: Utility to download and extract Roboflow YOLOv8 export\n",
        "def download_and_extract_roboflow_zip(roboflow_zip_url, extract_to=\"roboflow_dataset\"):\n",
        "    if os.path.exists(extract_to):\n",
        "        print(f\"'{extract_to}' already exists, skipping download.\")\n",
        "        return\n",
        "    print(\"Downloading dataset from Roboflow...\")\n",
        "    r = requests.get(roboflow_zip_url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(extract_to)\n",
        "    print(f\"Dataset extracted to '{extract_to}'.\")\n",
        "\n",
        "# Cell 4: YOLOv8 to COCO box conversion (helper)\n",
        "def yolo_to_coco(bbox, img_w, img_h):\n",
        "    # bbox: [x_center, y_center, width, height] normalized\n",
        "    x_c, y_c, w, h = bbox\n",
        "    x_c *= img_w\n",
        "    y_c *= img_h\n",
        "    w *= img_w\n",
        "    h *= img_h\n",
        "    # Convert to [xmin, ymin, xmax, ymax]\n",
        "    xmin = x_c - w / 2\n",
        "    ymin = y_c - h / 2\n",
        "    xmax = x_c + w / 2\n",
        "    ymax = y_c + h / 2\n",
        "    return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "# Cell 5: Roboflow YOLO8 Dataset\n",
        "class RoboflowYolo8Dataset(Dataset):\n",
        "    def __init__(self, data_dir, split='train', transforms=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Find image and label files\n",
        "        self.images_dir = os.path.join(self.data_dir, self.split, \"images\")\n",
        "        self.labels_dir = os.path.join(self.data_dir, self.split, \"labels\")\n",
        "        self.image_files = [f for f in os.listdir(self.images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        self.label_files = [f.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\").replace(\".jpeg\",\".txt\") for f in self.image_files]\n",
        "\n",
        "        # Build class list from data.yaml\n",
        "        self.class_dict = self._parse_class_names()\n",
        "\n",
        "    def _parse_class_names(self):\n",
        "        yaml_path = os.path.join(self.data_dir, \"data.yaml\")\n",
        "        import yaml\n",
        "        with open(yaml_path, \"r\") as f:\n",
        "            ydata = yaml.safe_load(f)\n",
        "        names = ydata.get(\"names\") or ydata.get(\"nc\")\n",
        "        if isinstance(names, dict):\n",
        "            names = [names[k] for k in sorted(names)]\n",
        "        return {name: idx for idx, name in enumerate(names)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        label_name = self.label_files[idx]\n",
        "        img_path = os.path.join(self.images_dir, img_name)\n",
        "        label_path = os.path.join(self.labels_dir, label_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        img_w, img_h = image.size\n",
        "\n",
        "        # Read label file (YOLO format)\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, \"r\") as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 5: continue\n",
        "                    cls_id = int(parts[0])\n",
        "                    bbox = list(map(float, parts[1:5]))\n",
        "                    box = yolo_to_coco(bbox, img_w, img_h)\n",
        "                    boxes.append(box)\n",
        "                    labels.append(cls_id+1)  # +1 for background=0 in FasterRCNN\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "        }\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        else:\n",
        "            image = F.to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "# Cell 6: Helper for collate_fn (required by DataLoader)\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af63557-92d2-456f-a93e-5d40c2a40ba9",
      "metadata": {
        "id": "5af63557-92d2-456f-a93e-5d40c2a40ba9"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Prepare the dataset\n",
        "# Set your Roboflow ZIP URL here (YOLOv8 format)\n",
        "ROBOFLOW_ZIP_URL = \"https://app.roboflow.com/ds/VquXPr9PVz?key=QyrlUzVsjR\"\n",
        "DATASET_DIR = \"roboflow_dataset\"\n",
        "download_and_extract_roboflow_zip(ROBOFLOW_ZIP_URL, extract_to=DATASET_DIR)\n",
        "\n",
        "# Prepare train/val datasets and dataloaders\n",
        "train_dataset = RoboflowYolo8Dataset(DATASET_DIR, split=\"train\")\n",
        "#val_dataset = RoboflowYolo8Dataset(DATASET_DIR, split=\"valid\")\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "#val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edaaef3b-581b-4f4a-abe0-a4887cb9f360",
      "metadata": {
        "id": "edaaef3b-581b-4f4a-abe0-a4887cb9f360"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Prepare the model\n",
        "def get_fasterrcnn_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "num_classes = len(train_dataset.class_dict) + 1  # +1 for background\n",
        "model = get_fasterrcnn_model(num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Cell 9: Training loop\n",
        "num_epochs = 10\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += losses.item()\n",
        "    print(f\"Epoch {epoch+1} - Average Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Cell 10: Save the trained model\n",
        "torch.save(model.state_dict(), \"fasterrcnn_roboflow_yolov8.pth\")\n",
        "print(\"Model saved as fasterrcnn_roboflow_yolov8.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f9ffda-86f6-4340-8c4c-a6479a10df29",
      "metadata": {
        "id": "00f9ffda-86f6-4340-8c4c-a6479a10df29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(\"roboflow_dataset\"):\n",
        "    print(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e134d97a-b1f7-4d94-92d1-aa76807c821a",
      "metadata": {
        "id": "e134d97a-b1f7-4d94-92d1-aa76807c821a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686ada09-fd4d-4ac7-8f7d-d0f9f1c4f630",
      "metadata": {
        "id": "686ada09-fd4d-4ac7-8f7d-d0f9f1c4f630",
        "outputId": "0efa3d43-c27b-4d8a-c7e1-5717bd490996"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/andylowther'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e209f41-1059-485a-aa4c-dc4f2ab0e934",
      "metadata": {
        "id": "6e209f41-1059-485a-aa4c-dc4f2ab0e934"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}